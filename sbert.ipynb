{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib; import psutil; _tmp = psutil.Process().parent().cmdline()\n",
    "print('CondaEnv:', pathlib.Path(_tmp[0]).parent.parent.stem, '|', [_tmp2 for _tmp2 in _tmp if '--port' in _tmp2], '|', _tmp)\n",
    "!jupyter notebook list\n",
    "!curl -sSLG localhost:8371/api/sessions --data-urlencode `jupyter notebook list | grep ':8371' | awk '/token/ {split($1,a,\"?\")} END {print a[2]}'`  | jq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<module 'dataset' from '/storage/arkareem/projects/classes/Penn-Tree-Bank-Project/dataset.py'>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try: mylibs\n",
    "except: mylibs = set()\n",
    "import importlib\n",
    "reload_my_libs = lambda : [importlib.reload(lib) for lib in mylibs]\n",
    "\n",
    "import dataset\n",
    "\n",
    "mylibs.add(dataset)\n",
    "reload_my_libs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShardingFilterIterDataPipe,\n",
       " ShardingFilterIterDataPipe,\n",
       " ShardingFilterIterDataPipe)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchtext\n",
    "torchtext.datasets.PennTreebank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import PennTreebank\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# Define a tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Load the Penn Treebank dataset\n",
    "train_dataset, valid_dataset, test_dataset = PennTreebank()\n",
    "\n",
    "# Build the vocabulary from the training dataset\n",
    "train_vocab = build_vocab_from_iterator(map(tokenizer, train_dataset), specials=[\"<unk>\", \"<pad>\"])\n",
    "\n",
    "# Define a function to numericalize the tokens\n",
    "def numericalize_tokens(tokens):\n",
    "    return [train_vocab.stoi[token] for token in tokens]\n",
    "\n",
    "# Define a function to preprocess a sentence\n",
    "def preprocess_sentence(sentence):\n",
    "    return numericalize_tokens(tokenizer(sentence))\n",
    "\n",
    "# Example usage:\n",
    "sentence = \"This is an example sentence.\"\n",
    "numericalized = preprocess_sentence(sentence)\n",
    "tensor = torch.tensor(numericalized)\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42068\n",
      "3370\n",
      "3761\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "from torchtext.datasets import PennTreebank\n",
    "\n",
    "# Load the PennTreebank dataset\n",
    "train_data = PennTreebank(split='train')\n",
    "valid_data = PennTreebank(split='valid')\n",
    "test_data = PennTreebank(split='test')\n",
    "\n",
    "# Print some examples\n",
    "print(len(list(train_data)))\n",
    "print(len(list(valid_data)))\n",
    "print(len(list(test_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum train 887521\n",
      "sum valid 70390\n",
      "sum test 78669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1036580"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('sum train', sum([len(sentence.split(' ')) for sentence in train_data]))\n",
    "print('sum valid', sum([len(sentence.split(' ')) for sentence in valid_data]))\n",
    "print('sum test', sum([len(sentence.split(' ')) for sentence in test_data]))\n",
    "887521+70390+78669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Tag sentences with spaCy\n",
    "for sentence in tqdm(list(train_data)):\n",
    "  doc = nlp(sentence)\n",
    "  words = [token.text for token in doc]\n",
    "  tags = [token.pos_ for token in doc]\n",
    "#   print(words, tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter\n",
      "pierre <unk> N years old will join the board as a nonexecutive director nov. N\n",
      "mr. <unk> is chairman of <unk> n.v. the dutch publishing group\n",
      "rudolph <unk> N years old and former chairman of consolidated gold fields plc was named a nonexecutive director of this british industrial conglomerate\n",
      "a form of asbestos once used to make kent cigarette filters has caused a high percentage of cancer deaths among a group of workers exposed to it more than N years ago researchers reported\n",
      "the asbestos fiber <unk> is unusually <unk> once it enters the <unk> with even brief exposures to it causing symptoms that show up decades later researchers said\n",
      "<unk> inc. the unit of new york-based <unk> corp. that makes kent cigarettes stopped using <unk> in its <unk> cigarette filters in N\n",
      "although preliminary findings were reported more than a year ago the latest results appear in today 's new england journal of medicine a forum likely to bring new attention to the problem\n",
      "a <unk> <unk> said this is an old story\n",
      "we 're talking about years ago before anyone heard of asbestos having any questionable properties\n",
      "there is no asbestos in our products now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/arkareem/libraries/conda/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/combining.py:297: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "for i, n in enumerate(train_data):\n",
    "    print(n)\n",
    "    if i == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ibm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir .data\n",
    "!wget -q -O .data/ptb.zip https://ibm.box.com/shared/static/z2yvmhbskc45xd2a9a4kkn6hg4g4kj5r.zip\n",
    "!unzip -o .data/ptb.zip -d .data\n",
    "!cp .data/ptb/reader.py .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'reader' from '/storage/arkareem/projects/classes/Penn-Tree-Bank-Project/reader.py'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import reader\n",
    "import importlib\n",
    "importlib.reload(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O .data/simple-examples.tgz http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
    "!mkdir .data/simple-examples\n",
    "!tar xzf .data/simple-examples.tgz -C .data/simple-examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929589\n",
      "73760\n",
      "82430\n"
     ]
    }
   ],
   "source": [
    "data_dir = \".data/simple-examples/simple-examples/data/\"\n",
    "raw_data = reader.ptb_raw_data(data_dir)\n",
    "train_data, valid_data, test_data, vocab, word_to_id = raw_data\n",
    "print(len(train_data))\n",
    "print(len(valid_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter', '<eos>', 'pierre', '<unk>', 'N', 'years', 'old', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', 'N', '<eos>', 'mr.', '<unk>', 'is', 'chairman', 'of', '<unk>', 'n.v.', 'the', 'dutch', 'publishing', 'group', '<eos>', 'rudolph', '<unk>', 'N', 'years', 'old', 'and', 'former', 'chairman', 'of', 'consolidated', 'gold', 'fields', 'plc', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'british', 'industrial', 'conglomerate', '<eos>', 'a', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of']\n"
     ]
    }
   ],
   "source": [
    "def id_to_word(id_list):\n",
    "    line = []\n",
    "    for w in id_list:\n",
    "        for word, wid in word_to_id.items():\n",
    "            if wid == w:\n",
    "                line.append(word)\n",
    "    return line            \n",
    "                \n",
    "\n",
    "print(id_to_word(train_data[0:100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[9970, 9971, 9972],\n",
       "        [   5, 2437,   54],\n",
       "        [   6,    1,  232],\n",
       "        [  34,   97, 4647],\n",
       "        [   0,  332, 7147],\n",
       "        [  18,  937, 1238],\n",
       "        [   2,  823,    1],\n",
       "        [   8,    1, 1716],\n",
       "        [   5,    6, 1969],\n",
       "        [  19,  484, 1112],\n",
       "        [5266,    7,  390],\n",
       "        [  53,  101,   26],\n",
       "        [ 554,   16,  850],\n",
       "        [   5,   25,  192],\n",
       "        [   1,    9,  161],\n",
       "        [  29,  466, 2028]], dtype=int32),\n",
       " array([[9971, 9972, 9974],\n",
       "        [2437,   54, 2155],\n",
       "        [   1,  232,   70],\n",
       "        [  97, 4647,   43],\n",
       "        [ 332, 7147,  328],\n",
       "        [ 937, 1238, 1340],\n",
       "        [ 823,    1,  376],\n",
       "        [   1, 1716,    6],\n",
       "        [   6, 1969,    0],\n",
       "        [ 484, 1112, 1666],\n",
       "        [   7,  390,   15],\n",
       "        [ 101,   26, 1378],\n",
       "        [  16,  850,    3],\n",
       "        [  25,  192,   18],\n",
       "        [   9,  161,  293],\n",
       "        [ 466, 2028,    7]], dtype=int32),\n",
       " (16, 3))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itera = reader.ptb_iterator(train_data, 16, 3)\n",
    "first_touple = itera.__next__()\n",
    "x = first_touple[0]\n",
    "y = first_touple[1]\n",
    "x, y, x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<module 'dataset' from '/storage/arkareem/projects/classes/Penn-Tree-Bank-Project/dataset.py'>,\n",
       " <module 'sbert' from '/storage/arkareem/projects/classes/Penn-Tree-Bank-Project/sbert.py'>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import sbert\n",
    "mylibs.add(sbert)\n",
    "reload_my_libs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33markareem\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "!wandb login  # copy the key from https://wandb.ai/authorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.get_treebank_3914()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2'\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "sbert_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "sbert_model = AutoModel.from_pretrained('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "sbert_model = sbert_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:15<00:00,  3.14it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3131/3131 [00:04<00:00, 685.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 783/783 [00:01<00:00, 677.55it/s]\n"
     ]
    }
   ],
   "source": [
    "embeds, attn_masks = sbert.sbert_encode_batched(sbert_model, sbert_tokenizer, [' '.join(x) for x in data['train_sentences']], 64)\n",
    "train_embeds_pooled = sbert.pool_tokens(data['train_sentences'], embeds, attn_masks, sbert_tokenizer)\n",
    "\n",
    "embeds, attn_masks = sbert.sbert_encode_batched(sbert_model, sbert_tokenizer, [' '.join(x) for x in data['test_sentences']], 64)\n",
    "test_embeds_pooled = sbert.pool_tokens(data['test_sentences'], embeds, attn_masks, sbert_tokenizer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear cuda cache\n",
    "# torch.cuda.empty_cache()\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['all_pos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing embeds would take: 1.15 GB\n",
      "Wasted: 27.4%\n",
      "torch.Size([3131, 128, 768]) torch.Size([3131, 128])\n",
      "The following sentences are longer than the maximum of 128 tokens:\n",
      "\t John William Davis , Colonsville , Miss. , fined *-4 $ 200,000 *U* ; Jeffrey Gerard Dompierre , Valrico , Fla. , $ 5,000 *U* and 10-day suspension ; Eugene Michael Felten , La Canada , Calif. , fined *-3 $ 25,000 *U* , ordered *-3 *-2 to disgorge $ 16,072 *U* and suspended *-3 one year ; Marion Stewart Spitler , La Canada , fined *-5 $ 15,000 *U* , ordered *-5 *-1 to disgorge $ 18,444 *U* and suspended *-5 six months .\n",
      "\t Charles D. Phipps Sr. , Hermitage , Pa. , fined *-1 $ 10,000 *U* ; David Scott Rankin , Lake St. Louis , Mo. , $ 15,000 *U* ; Leigh A. Sanderoff , Gaithersburg , Md. , fined *-2 $ 45,000 *U* , ordered *-2 *-3 to disgorge $ 12,252 *U* ; Sandra Ann Smith , Ridgefield , N.J. , $ 15,000 *U* ; James G. Spence , Aloha , Ore. , $ 5,000 *U* and six-month suspension ; Mona Sun , Jamaica Estates , N.Y. , $ 60,000 *U* ; William Swearingen , Minneapolis , $ 15,000 *U* and six-month suspension ; John Bew Wong , San Francisco , $ 25,000 *U* ; Rabia M. Zayed , San Francisco , $ 50,000 *U* .\n",
      "\t For years , this group included a stable of classics -- Bordeaux first growths -LRB- Lafite-Rothschild , Latour , Haut-Brion , Petrus -RRB- , Grand Cru Burgundies -LRB- Romanee-Conti and La Tache -RRB- deluxe Champagnes -LRB- Dom Perignon or Roederer Cristal -RRB- , rarefied sweet wines -LRB- Chateau Yquem or Trockenbeerenauslesen Rieslings from Germany , and Biondi-Santi Brunello Riserva from Tuscany -RRB- .\n",
      "\t Andrew Derel Adams , Killeen , Texas , fined *-1 $ 15,000 *U* ; John Francis Angier Jr. , Reddington Shores , Fla. , $ 15,000 *U* ; Mark Anthony , Arlington Heights , Ill. , $ 10,000 *U* and 30-day suspension ; William Stirlen , Arlington Heights , Ill. , $ 7,500 *U* and 30-day suspension ; Fred W. Bonnell , Boulder , Colo. , $ 2,500 *U* and six-month suspension ; Michael J. Boorse , Horsham , Pa. ; David Chiodo , Dallas , $ 5,000 *U* , barred *-3 as a principal ; Camille Chafic Cotran , London , $ 25,000 *U* ; John William Curry , fined *-4 $ 5,000 *U* , ordered *-4 *-2 to disgorge $ 30,000 *U* , one-year suspension .\n",
      "\t The following *ICH*-4 were barred *-3 or , where * noted *-1 *T*-2 , suspended *-3 and consented to findings without *-3 admitting or denying wrongdoing : Edward L. Cole , Jackson , Miss. , $ 10,000 *U* fine ; Rita Rae Cross , Denver , $ 2,500 *U* fine and 30-day suspension ; Thomas Richard Meinders , Colorado Springs , Colo. , $ 2,000 *U* fine , five-day suspension and eight-month suspension as a principal ; Ronald A. Cutrer , Baton Rouge , La. , $ 15,000 *U* fine and one-month suspension ; Karl Grant Hale , Midvale , Utah , $ 15,000 *U* fine ; Clinton P. Hayne , New Orleans , $ 7,500 *U* fine and one-week suspension ; Richard M. Kane , Coconut Creek , Fla. , $ 250,000 *U* fine ; John B. Merrick , Aurora , Colo. , $ 1,000 *U* fine and 10-day suspension ; John P. Miller , Baton Rouge , $ 2,000 *U* fine and two-week suspension ; Randolph K. Pace , New York , $ 10,000 *U* fine and 90-day suspension ; Brian D. Pitcher , New Providence , N.J. , $ 30,000 *U* fine ; Wayne A. Russo , Bridgeville , Pa. , $ 4,000 *U* fine and 15-day suspension ; Orville Leroy Sandberg , Aurora , Colo. , $ 3,500 *U* fine and 10-day suspension ; Richard T. Marchese , Las Vegas , Nev. , $ 5,000 *U* and one-year suspension ; Eric G. Monchecourt , Las Vegas , $ 5,000 *U* and one-year suspension ; and Robert Gerhard Smith , Carson City , Nev. , two-year suspension .\n",
      "\t *-1 Offering the wine at roughly $ 65 *U* a bottle wholesale -LRB- $ 100 *U* retail -RRB- , he sent merchants around the country a form asking them *-2 to check one of three answers : 1 -RRB- no , the wine is too high -LRB- 2 responses -RRB- ; 2 -RRB- yes , it 's high but I 'll take it -LRB- 2 responses -RRB- ; 3 -RRB- I 'll take all 0 I can get *T*-3 -LRB- 58 responses -RRB- .\n",
      "\t The following *ICH*-2 were neither barred nor suspended *-1 : Stephanie Veselich Enright , Rolling Hills , Calif. , fined *-3 $ 2,500 *U* and ordered *-3 *-4 to disgorge $ 11,762 *U* ; Stuart Lane Russel , Glendale , Calif. , fined *-5 $ 2,500 *U* and ordered *-5 *-6 to disgorge $ 14,821 *U* ; Devon Nilson Dahl , Fountain Valley , Calif. , fined *-7 $ 82,389 *U* .\n"
     ]
    }
   ],
   "source": [
    "embeds, attn_masks = sbert.sbert_encode_batched(sbert_model, sbert_tokenizer, [' '.join(x) for x in data['train_sentences']], 64)\n",
    "\n",
    "print(f'Storing embeds would take: {embeds.numel() * 4 / 1024 / 1024 / 1024:.2f} GB')\n",
    "print(f'Wasted: {100*attn_masks.sum().item() / attn_masks.numel():.1f}%')\n",
    "print(embeds.shape, attn_masks.shape)\n",
    "\n",
    "\n",
    "print('The following sentences are longer than the maximum of 128 tokens:')\n",
    "sent_id_overlen = torch.where(attn_masks[:, -1] == 1)[0]\n",
    "for i in sent_id_overlen:\n",
    "    print('\\t', ' '.join(data['train_sentences'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
      "untokenized ['<s>', 'pierre', 'vin', '##ken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'none', '##x', '##ec', '##utive', 'director', 'nov', '.', '29', '.', '</s>']\n",
      "??? what is this in the test set ['@']\n"
     ]
    }
   ],
   "source": [
    "# data['train_sentences']\n",
    "i = 0\n",
    "e = embeds[i, attn_masks[i]==1]\n",
    "e.shape[0], len(data['train_sentences'][i])\n",
    "\n",
    "print('sent', data['train_sentences'][i])\n",
    "print('untokenized', sbert_tokenizer.convert_ids_to_tokens(sbert_tokenizer.encode_plus(' '.join(data['train_sentences'][i]))['input_ids']))\n",
    "\n",
    "print('??? what is this in the test set', data['test_sentences'][739])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = sbert.ListDataset(train_embeds_pooled, data['train_tags'], data['all_pos'])\n",
    "test_dataset = sbert.ListDataset(test_embeds_pooled, data['test_tags'], data['all_pos'])\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)\n",
    "test_dataset = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common: 20 NN\n",
      "predicting most common pos would be 13.024323885831244\n"
     ]
    }
   ],
   "source": [
    "# get most common pos\n",
    "pos_counts = np.bincount([y for n in train_dataset.dataset.data for y in n[3]])\n",
    "print('most common:', pos_counts.argmax(), data['all_pos'][pos_counts.argmax()])\n",
    "print('predicting most common pos would be', 100*pos_counts[pos_counts.argmax()]/pos_counts.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable #p: 208,686\n"
     ]
    }
   ],
   "source": [
    "reload_my_libs()\n",
    "\n",
    "model_config = {\n",
    "    'input_dim': 768, \n",
    "    'hidden_dims': [256],\n",
    "    'output_dim': len(data['all_pos'])\n",
    "}\n",
    "\n",
    "model = sbert.SimpleModel(model_config).to(device)\n",
    "param_count = sum([p.numel() for n,p in model.named_parameters()])\n",
    "print(f'trainable #p: {param_count:,}')\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay = 0.0001\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion_ce = torch.nn.CrossEntropyLoss()\n",
    "cur_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33markareem\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/storage/arkareem/projects/classes/Penn-Tree-Bank-Project/wandb/run-20230502_024123-56j504lz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arkareem/6.8630%20Penn%20Treebank%20Project/runs/56j504lz' target=\"_blank\">helpful-aardvark-5</a></strong> to <a href='https://wandb.ai/arkareem/6.8630%20Penn%20Treebank%20Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arkareem/6.8630%20Penn%20Treebank%20Project' target=\"_blank\">https://wandb.ai/arkareem/6.8630%20Penn%20Treebank%20Project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arkareem/6.8630%20Penn%20Treebank%20Project/runs/56j504lz' target=\"_blank\">https://wandb.ai/arkareem/6.8630%20Penn%20Treebank%20Project/runs/56j504lz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/arkareem/6.8630%20Penn%20Treebank%20Project/runs/56j504lz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f72524bc0d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"6.8630 Penn Treebank Project\", config={\n",
    "    \"architecture\": \"SimpleModel\",\n",
    "    \"dataset\": \"treebank_3914\",\n",
    "\n",
    "    \"learning_rate\": lr,\n",
    "    'weight_decay': weight_decay,\n",
    "    \"model_config\": model_config,\n",
    "    \"#params\": param_count,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 Acc: 98.5% Loss: 0.087210: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 89.26it/s]\n",
      "Val Epoch: 100 Acc: 90.7% Loss: 0.310953: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 99.39it/s]\n",
      "Train Epoch: 101 Acc: 98.7% Loss: 0.082894: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 113.38it/s]\n",
      "Val Epoch: 101 Acc: 90.6% Loss: 0.320495: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 103.17it/s]\n",
      "Train Epoch: 102 Acc: 98.5% Loss: 0.091605: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 89.64it/s]\n",
      "Val Epoch: 102 Acc: 90.9% Loss: 0.312954: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 152.89it/s]\n",
      "Train Epoch: 103 Acc: 98.6% Loss: 0.083903: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 100.14it/s]\n",
      "Val Epoch: 103 Acc: 90.7% Loss: 0.321664: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 101.77it/s]\n",
      "Train Epoch: 104 Acc: 98.5% Loss: 0.095185: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 101.33it/s]\n",
      "Val Epoch: 104 Acc: 90.7% Loss: 0.313620: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 105.46it/s]\n",
      "Train Epoch: 105 Acc: 98.7% Loss: 0.082055: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 90.21it/s]\n",
      "Val Epoch: 105 Acc: 90.8% Loss: 0.314027: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 97.90it/s]\n",
      "Train Epoch: 106 Acc: 98.5% Loss: 0.087051: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 108.49it/s]\n",
      "Val Epoch: 106 Acc: 90.8% Loss: 0.316039: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 101.36it/s]\n",
      "Train Epoch: 107 Acc: 98.8% Loss: 0.081274: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 86.22it/s]\n",
      "Val Epoch: 107 Acc: 90.9% Loss: 0.318078: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 204.80it/s]\n",
      "Train Epoch: 108 Acc: 98.6% Loss: 0.087243: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 86.35it/s]\n",
      "Val Epoch: 108 Acc: 90.7% Loss: 0.321611: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 77.18it/s]\n",
      "Train Epoch: 109 Acc: 98.7% Loss: 0.082585: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 86.11it/s]\n",
      "Val Epoch: 109 Acc: 90.5% Loss: 0.315824: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 88.16it/s]\n",
      "Train Epoch: 110 Acc: 98.7% Loss: 0.079100: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 87.35it/s]\n",
      "Val Epoch: 110 Acc: 90.9% Loss: 0.312479: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 223.56it/s]\n",
      "Train Epoch: 111 Acc: 98.8% Loss: 0.078329: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 87.22it/s]\n",
      "Val Epoch: 111 Acc: 90.6% Loss: 0.322505: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 107.09it/s]\n",
      "Train Epoch: 112 Acc: 98.7% Loss: 0.078996: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 96.52it/s]\n",
      "Val Epoch: 112 Acc: 90.8% Loss: 0.320998: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 88.76it/s]\n",
      "Train Epoch: 113 Acc: 98.6% Loss: 0.084305: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 79.92it/s]\n",
      "Val Epoch: 113 Acc: 90.7% Loss: 0.316272: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 188.18it/s]\n",
      "Train Epoch: 114 Acc: 98.7% Loss: 0.089053: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 79.54it/s]\n",
      "Val Epoch: 114 Acc: 90.8% Loss: 0.316671: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 61.84it/s]\n",
      "Train Epoch: 115 Acc: 98.7% Loss: 0.085038: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 93.58it/s]\n",
      "Val Epoch: 115 Acc: 90.8% Loss: 0.316452: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 81.75it/s]\n",
      "Train Epoch: 116 Acc: 98.8% Loss: 0.082390: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 93.48it/s]\n",
      "Val Epoch: 116 Acc: 90.7% Loss: 0.318551: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 114.04it/s]\n",
      "Train Epoch: 117 Acc: 98.7% Loss: 0.080682: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 86.44it/s]\n",
      "Val Epoch: 117 Acc: 90.8% Loss: 0.316407: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 82.73it/s]\n",
      "Train Epoch: 118 Acc: 98.9% Loss: 0.076906: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 100.66it/s]\n",
      "Val Epoch: 118 Acc: 90.7% Loss: 0.314936: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 98.27it/s]\n",
      "Train Epoch: 119 Acc: 99.0% Loss: 0.072010: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 88.47it/s]\n",
      "Val Epoch: 119 Acc: 90.7% Loss: 0.319342: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 243.95it/s]\n",
      "Train Epoch: 120 Acc: 98.8% Loss: 0.078469: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 93.70it/s]\n",
      "Val Epoch: 120 Acc: 90.7% Loss: 0.318778: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 108.88it/s]\n",
      "Train Epoch: 121 Acc: 98.9% Loss: 0.072687: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 92.09it/s]\n",
      "Val Epoch: 121 Acc: 90.8% Loss: 0.316144: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 107.91it/s]\n",
      "Train Epoch: 122 Acc: 99.0% Loss: 0.070395: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 85.04it/s]\n",
      "Val Epoch: 122 Acc: 90.8% Loss: 0.314880: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 110.16it/s]\n",
      "Train Epoch: 123 Acc: 99.0% Loss: 0.068729: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 87.43it/s]\n",
      "Val Epoch: 123 Acc: 90.8% Loss: 0.317930: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 87.15it/s]\n",
      "Train Epoch: 124 Acc: 99.0% Loss: 0.076673: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 94.18it/s]\n",
      "Val Epoch: 124 Acc: 90.8% Loss: 0.319600: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 99.86it/s]\n",
      "Train Epoch: 125 Acc: 99.1% Loss: 0.072808: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 81.65it/s]\n",
      "Val Epoch: 125 Acc: 90.8% Loss: 0.317158: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 123.73it/s]\n",
      "Train Epoch: 126 Acc: 98.8% Loss: 0.075274: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 92.72it/s]\n",
      "Val Epoch: 126 Acc: 90.6% Loss: 0.320679: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 97.98it/s]\n",
      "Train Epoch: 127 Acc: 99.0% Loss: 0.074935: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 96.94it/s]\n",
      "Val Epoch: 127 Acc: 90.8% Loss: 0.315348: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 70.27it/s]\n",
      "Train Epoch: 128 Acc: 99.1% Loss: 0.070931: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 73.24it/s]\n",
      "Val Epoch: 128 Acc: 90.4% Loss: 0.330854: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 133.92it/s]\n",
      "Train Epoch: 129 Acc: 98.6% Loss: 0.091910: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 87.75it/s]\n",
      "Val Epoch: 129 Acc: 90.1% Loss: 0.347627: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 116.35it/s]\n",
      "Train Epoch: 130 Acc: 98.6% Loss: 0.087772: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 95.06it/s]\n",
      "Val Epoch: 130 Acc: 90.7% Loss: 0.321990: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 105.87it/s]\n",
      "Train Epoch: 131 Acc: 99.0% Loss: 0.076501: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 90.15it/s]\n",
      "Val Epoch: 131 Acc: 90.7% Loss: 0.320209: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 119.90it/s]\n",
      "Train Epoch: 132 Acc: 99.0% Loss: 0.069558: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 96.06it/s]\n",
      "Val Epoch: 132 Acc: 90.6% Loss: 0.324974: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 100.25it/s]\n",
      "Train Epoch: 133 Acc: 99.0% Loss: 0.077056: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 103.37it/s]\n",
      "Val Epoch: 133 Acc: 90.8% Loss: 0.322487: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 105.69it/s]\n",
      "Train Epoch: 134 Acc: 99.0% Loss: 0.073531: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 93.92it/s]\n",
      "Val Epoch: 134 Acc: 90.9% Loss: 0.319546: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 92.79it/s]\n",
      "Train Epoch: 135 Acc: 98.9% Loss: 0.072977: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 114.78it/s]\n",
      "Val Epoch: 135 Acc: 90.6% Loss: 0.319563: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 102.51it/s]\n",
      "Train Epoch: 136 Acc: 99.1% Loss: 0.069493: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 89.35it/s]\n",
      "Val Epoch: 136 Acc: 90.7% Loss: 0.316927: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 118.43it/s]\n",
      "Train Epoch: 137 Acc: 99.2% Loss: 0.065885: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 93.22it/s]\n",
      "Val Epoch: 137 Acc: 90.8% Loss: 0.315427: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 106.22it/s]\n",
      "Train Epoch: 138 Acc: 99.2% Loss: 0.067151: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 91.88it/s]\n",
      "Val Epoch: 138 Acc: 90.8% Loss: 0.319834: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 93.10it/s]\n",
      "Train Epoch: 139 Acc: 99.2% Loss: 0.064165: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 78.47it/s]\n",
      "Val Epoch: 139 Acc: 90.8% Loss: 0.320776: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 103.26it/s]\n",
      "Train Epoch: 140 Acc: 99.0% Loss: 0.069303: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 91.61it/s]\n",
      "Val Epoch: 140 Acc: 90.6% Loss: 0.329699: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 98.30it/s]\n",
      "Train Epoch: 141 Acc: 99.1% Loss: 0.069885: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 99.05it/s]\n",
      "Val Epoch: 141 Acc: 90.7% Loss: 0.320249: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 94.66it/s]\n",
      "Train Epoch: 142 Acc: 99.2% Loss: 0.066806: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 86.18it/s]\n",
      "Val Epoch: 142 Acc: 90.8% Loss: 0.319003: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 106.83it/s]\n",
      "Train Epoch: 143 Acc: 99.3% Loss: 0.063640: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 104.44it/s]\n",
      "Val Epoch: 143 Acc: 90.7% Loss: 0.319950: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 104.66it/s]\n",
      "Train Epoch: 144 Acc: 99.2% Loss: 0.063057: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 91.37it/s]\n",
      "Val Epoch: 144 Acc: 90.6% Loss: 0.318175: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 99.43it/s]\n",
      "Train Epoch: 145 Acc: 99.2% Loss: 0.067975: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 85.74it/s]\n",
      "Val Epoch: 145 Acc: 90.6% Loss: 0.322141: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 82.33it/s]\n",
      "Train Epoch: 146 Acc: 99.2% Loss: 0.064336: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 91.98it/s]\n",
      "Val Epoch: 146 Acc: 90.8% Loss: 0.323395: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 100.37it/s]\n",
      "Train Epoch: 147 Acc: 99.2% Loss: 0.070158: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 98.81it/s]\n",
      "Val Epoch: 147 Acc: 90.8% Loss: 0.316567: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 127.23it/s]\n",
      "Train Epoch: 148 Acc: 99.1% Loss: 0.065391: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 83.91it/s]\n",
      "Val Epoch: 148 Acc: 90.8% Loss: 0.317399: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 81.65it/s]\n",
      "Train Epoch: 149 Acc: 99.3% Loss: 0.060308: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 99.02it/s]\n",
      "Val Epoch: 149 Acc: 90.8% Loss: 0.314735: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 105.40it/s]\n",
      "Train Epoch: 150 Acc: 99.3% Loss: 0.060589: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 89.69it/s]\n",
      "Val Epoch: 150 Acc: 90.7% Loss: 0.317336: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 196.80it/s]\n",
      "Train Epoch: 151 Acc: 99.3% Loss: 0.062350: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 93.20it/s]\n",
      "Val Epoch: 151 Acc: 90.8% Loss: 0.318414: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 104.10it/s]\n",
      "Train Epoch: 152 Acc: 99.2% Loss: 0.063123: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 129.40it/s]\n",
      "Val Epoch: 152 Acc: 90.8% Loss: 0.314594: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 234.07it/s]\n",
      "Train Epoch: 153 Acc: 99.4% Loss: 0.057981: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 181.47it/s]\n",
      "Val Epoch: 153 Acc: 90.6% Loss: 0.323478: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 252.95it/s]\n",
      "Train Epoch: 154 Acc: 99.2% Loss: 0.063599: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 154.95it/s]\n",
      "Val Epoch: 154 Acc: 90.8% Loss: 0.316768: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 98.77it/s]\n",
      "Train Epoch: 155 Acc: 99.4% Loss: 0.059956: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 111.28it/s]\n",
      "Val Epoch: 155 Acc: 90.6% Loss: 0.317824: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 97.62it/s]\n",
      "Train Epoch: 156 Acc: 99.0% Loss: 0.066465: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 82.08it/s]\n",
      "Val Epoch: 156 Acc: 90.8% Loss: 0.319187: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 108.93it/s]\n",
      "Train Epoch: 157 Acc: 99.3% Loss: 0.061472: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 96.58it/s]\n",
      "Val Epoch: 157 Acc: 90.6% Loss: 0.320435: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 94.12it/s]\n",
      "Train Epoch: 158 Acc: 99.2% Loss: 0.064347: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 90.92it/s]\n",
      "Val Epoch: 158 Acc: 90.8% Loss: 0.316671: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 90.20it/s]\n",
      "Train Epoch: 159 Acc: 99.4% Loss: 0.059033: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 81.23it/s]\n",
      "Val Epoch: 159 Acc: 90.6% Loss: 0.323238: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 97.43it/s]\n",
      "Train Epoch: 160 Acc: 99.1% Loss: 0.069856: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 74.16it/s]\n",
      "Val Epoch: 160 Acc: 90.6% Loss: 0.323285: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 87.11it/s]\n",
      "Train Epoch: 161 Acc: 99.3% Loss: 0.062161: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 97.88it/s]\n",
      "Val Epoch: 161 Acc: 90.8% Loss: 0.320416: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 105.70it/s]\n",
      "Train Epoch: 162 Acc: 99.3% Loss: 0.060849: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 77.82it/s]\n",
      "Val Epoch: 162 Acc: 90.7% Loss: 0.320499: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 214.37it/s]\n",
      "Train Epoch: 163 Acc: 99.3% Loss: 0.064952: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 72.98it/s]\n",
      "Val Epoch: 163 Acc: 90.7% Loss: 0.320097: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 84.43it/s]\n",
      "Train Epoch: 164 Acc: 99.3% Loss: 0.062297: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 93.85it/s]\n",
      "Val Epoch: 164 Acc: 90.6% Loss: 0.333258: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 79.48it/s]\n",
      "Train Epoch: 165 Acc: 99.1% Loss: 0.071094: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 74.79it/s]\n",
      "Val Epoch: 165 Acc: 90.7% Loss: 0.320945: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 60.36it/s]\n",
      "Train Epoch: 166 Acc: 99.2% Loss: 0.065175: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 78.26it/s]\n",
      "Val Epoch: 166 Acc: 90.9% Loss: 0.316296: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 91.53it/s]\n",
      "Train Epoch: 167 Acc: 99.4% Loss: 0.055270: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 68.02it/s]\n",
      "Val Epoch: 167 Acc: 90.8% Loss: 0.320426: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 111.57it/s]\n",
      "Train Epoch: 168 Acc: 99.4% Loss: 0.058123: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 78.29it/s]\n",
      "Val Epoch: 168 Acc: 90.9% Loss: 0.318942: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 72.84it/s]\n",
      "Train Epoch: 169 Acc: 99.3% Loss: 0.059557: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 84.62it/s]\n",
      "Val Epoch: 169 Acc: 90.9% Loss: 0.319376: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 92.92it/s]\n",
      "Train Epoch: 170 Acc: 99.3% Loss: 0.061707: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 73.21it/s]\n",
      "Val Epoch: 170 Acc: 91.0% Loss: 0.315499: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 81.93it/s]\n",
      "Train Epoch: 171 Acc: 99.3% Loss: 0.059607: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 71.84it/s]\n",
      "Val Epoch: 171 Acc: 90.5% Loss: 0.331439: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 212.52it/s]\n",
      "Train Epoch: 172 Acc: 99.2% Loss: 0.067746: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 84.46it/s]\n",
      "Val Epoch: 172 Acc: 90.7% Loss: 0.319016: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 96.76it/s]\n",
      "Train Epoch: 173 Acc: 99.3% Loss: 0.059770: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 73.17it/s]\n",
      "Val Epoch: 173 Acc: 90.7% Loss: 0.324223: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 94.19it/s]\n",
      "Train Epoch: 174 Acc: 99.3% Loss: 0.065865: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 74.63it/s]\n",
      "Val Epoch: 174 Acc: 90.6% Loss: 0.322213: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 80.78it/s]\n",
      "Train Epoch: 175 Acc: 99.3% Loss: 0.059617: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 71.46it/s]\n",
      "Val Epoch: 175 Acc: 90.9% Loss: 0.319809: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 88.49it/s]\n",
      "Train Epoch: 176 Acc: 99.4% Loss: 0.055509: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 68.70it/s]\n",
      "Val Epoch: 176 Acc: 90.9% Loss: 0.318895: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 122.55it/s]\n",
      "Train Epoch: 177 Acc: 99.4% Loss: 0.055894: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 79.96it/s]\n",
      "Val Epoch: 177 Acc: 90.8% Loss: 0.320106: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 72.05it/s]\n",
      "Train Epoch: 178 Acc: 99.4% Loss: 0.062205: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 95.48it/s]\n",
      "Val Epoch: 178 Acc: 90.7% Loss: 0.317829: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 43.27it/s]\n",
      "Train Epoch: 179 Acc: 99.2% Loss: 0.061825: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 78.96it/s]\n",
      "Val Epoch: 179 Acc: 90.8% Loss: 0.321200: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 80.86it/s]\n",
      "Train Epoch: 180 Acc: 99.4% Loss: 0.059262: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 77.37it/s]\n",
      "Val Epoch: 180 Acc: 90.9% Loss: 0.319558: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 117.59it/s]\n",
      "Train Epoch: 181 Acc: 99.4% Loss: 0.056488: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 77.75it/s]\n",
      "Val Epoch: 181 Acc: 90.8% Loss: 0.318491: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 83.84it/s]\n",
      "Train Epoch: 182 Acc: 99.4% Loss: 0.058697: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 83.60it/s]\n",
      "Val Epoch: 182 Acc: 90.8% Loss: 0.321566: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 87.73it/s]\n",
      "Train Epoch: 183 Acc: 99.1% Loss: 0.065494: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 72.37it/s]\n",
      "Val Epoch: 183 Acc: 90.8% Loss: 0.321749: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 93.95it/s]\n",
      "Train Epoch: 184 Acc: 99.3% Loss: 0.067937: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 85.26it/s]\n",
      "Val Epoch: 184 Acc: 90.6% Loss: 0.320931: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 101.44it/s]\n",
      "Train Epoch: 185 Acc: 99.2% Loss: 0.067912: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 84.54it/s]\n",
      "Val Epoch: 185 Acc: 90.7% Loss: 0.318778: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 71.19it/s]\n",
      "Train Epoch: 186 Acc: 99.4% Loss: 0.054794: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 83.67it/s]\n",
      "Val Epoch: 186 Acc: 90.8% Loss: 0.318709: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 92.10it/s]\n",
      "Train Epoch: 187 Acc: 98.8% Loss: 0.070630: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 78.41it/s]\n",
      "Val Epoch: 187 Acc: 90.7% Loss: 0.321490: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 89.21it/s]\n",
      "Train Epoch: 188 Acc: 99.3% Loss: 0.062600: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 80.04it/s]\n",
      "Val Epoch: 188 Acc: 90.6% Loss: 0.327289: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 176.44it/s]\n",
      "Train Epoch: 189 Acc: 99.3% Loss: 0.062817: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 62.49it/s]\n",
      "Val Epoch: 189 Acc: 90.7% Loss: 0.332079: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 88.71it/s]\n",
      "Train Epoch: 190 Acc: 99.3% Loss: 0.064870: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 85.35it/s]\n",
      "Val Epoch: 190 Acc: 90.7% Loss: 0.320353: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 68.00it/s]\n",
      "Train Epoch: 191 Acc: 99.3% Loss: 0.060900: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 90.54it/s]\n",
      "Val Epoch: 191 Acc: 90.6% Loss: 0.325206: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 81.09it/s]\n",
      "Train Epoch: 192 Acc: 99.4% Loss: 0.060870: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 74.91it/s]\n",
      "Val Epoch: 192 Acc: 90.8% Loss: 0.318511: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 91.55it/s]\n",
      "Train Epoch: 193 Acc: 99.1% Loss: 0.072792: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 68.33it/s]\n",
      "Val Epoch: 193 Acc: 90.6% Loss: 0.323158: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 132.79it/s]\n",
      "Train Epoch: 194 Acc: 99.4% Loss: 0.060301: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 76.65it/s]\n",
      "Val Epoch: 194 Acc: 90.8% Loss: 0.320452: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 65.48it/s]\n",
      "Train Epoch: 195 Acc: 99.4% Loss: 0.054200: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 71.46it/s]\n",
      "Val Epoch: 195 Acc: 90.8% Loss: 0.318034: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 92.00it/s]\n",
      "Train Epoch: 196 Acc: 99.3% Loss: 0.064179: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 92.44it/s]\n",
      "Val Epoch: 196 Acc: 90.7% Loss: 0.327437: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 98.97it/s]\n",
      "Train Epoch: 197 Acc: 99.3% Loss: 0.064097: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 77.15it/s]\n",
      "Val Epoch: 197 Acc: 90.8% Loss: 0.321500: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 159.14it/s]\n",
      "Train Epoch: 198 Acc: 99.4% Loss: 0.057505: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 76.22it/s]\n",
      "Val Epoch: 198 Acc: 90.8% Loss: 0.320152: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 61.48it/s]\n",
      "Train Epoch: 199 Acc: 99.4% Loss: 0.058911: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 86.13it/s]\n",
      "Val Epoch: 199 Acc: 90.7% Loss: 0.323130: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 99.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    train_acc = sbert.single_epoch(model, train_dataset, criterion_ce, epoch=cur_epoch, optim=optim, is_train=True, device=device)\n",
    "    val_acc = sbert.single_epoch(model, test_dataset, criterion_ce, epoch=cur_epoch, optim=None, is_train=False, device=device)\n",
    "    if val_acc > float(sbert.read_json_prop('best_val')):\n",
    "        sbert.write_json_prop('best_val', val_acc)\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print('---saved best model---')\n",
    "    cur_epoch += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
